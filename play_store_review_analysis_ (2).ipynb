{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name : Play store app review analysis**"
      ],
      "metadata": {
        "id": "DxrKmtKo05g3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project Tpye : EDA\n",
        "\n",
        "Contribution : Individual\n",
        "\n",
        "Team Member: Snehal dapke.\n",
        "\n"
      ],
      "metadata": {
        "id": "4mZuGCaZ1F6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summery :**"
      ],
      "metadata": {
        "id": "h7XePHUO1SSf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncb-bGFwjGnH"
      },
      "source": [
        "**Android has over 2.8 billion active users, it has a global market share of 75 percent Android holds over 85% market share in Brazil, India, Indonesia, Turkey and Vietnam Over one billion Android smartphones were shipped last year Samsung is the largest Android smartphone manufacturer, followed by Huawei and Xiaomi.**\n",
        "\n",
        "\n",
        "**The main purpose of this project is to analyse and get information of app on play store data which provides some usefull output such as app features to improve market of android.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GitHub Link :\n",
        "https://github.com/Snehaldapke25/Play-store-app-Review-Analysis-EDA-.\n"
      ],
      "metadata": {
        "id": "NPtXekd708-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement:**"
      ],
      "metadata": {
        "id": "VkbR0NNf062A"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSvmNm3JjHmX"
      },
      "source": [
        "1. Play store data (main dataset)\n",
        "\n",
        "This contains data on the Google Play applications. It has 10,841 rows of data witch has following columns:\n",
        "\n",
        "*  App Category: Category of the app. This could be beauty, business, medical,art and design entertainment, education...etc.\n",
        "\n",
        "*  Rating: It has How users rate the app out of 5, with 1 being the lowest rating and 5 being the highest.\n",
        "\n",
        "*  Reviews: number of user reviews each app has received.\n",
        "\n",
        "*  Size: The memory size needed to install the application.\n",
        "\n",
        "*  Installs: The number of times each application has been installed by users.\n",
        "\n",
        "*  Type: Whether the app is free or a paid app.\n",
        "\n",
        "*  Price: The price of the app.\n",
        "\n",
        "*  Content Rating: This column specifies the intended audience for the app. Can be for teens, mature audience, or everyone.\n",
        "\n",
        "*  Genres: The sub-category for each app. Example: for the Education category, this could be Education: Pretend Play, for example.\n",
        "\n",
        "*  Last Updated: Release date of the most recent update for the app.\n",
        "\n",
        "*  Current Ver: The app's current version.\n",
        "\n",
        "*  Android Ver: The oldest version of Android OS supported by the app.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJsNi8onjHsc"
      },
      "source": [
        "2. Sentiment Analysis\n",
        "\n",
        "This file contains the result of the sentiment analysis conducted by the dataset creator. It has 64,295 rows of data with the following columns:\n",
        "\n",
        "*  App : Name of the app.\n",
        "\n",
        "*  Translated_Review: Either the original review in English, or a translated version if the orignal review is in another language.\n",
        "\n",
        "*  Sentiment: The result of the sentiment analysis conducted on a review. The value is either Positive, Neutral or Negative.\n",
        "\n",
        "*  Sentiment_Polarity: A value indicating the positivity or negativity of the sentiment, values range from -1 (most negative) to 1 (most positive).\n",
        "Sentiment polarity for an element defines the orientation of the expressed sentiment, i.e. it determines if the text expresses the positive, negative or neutral sentiment of the user about the entity in consideration.\n",
        "\n",
        "*  Sentiment_Subjectivity: A value from 0 to 1 indicating the subjectivity of the review. Lower values indicate the review is based on factual information, and higher values indicate the review is based on personal or public opinions or judgements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJyzOJj8BFnk"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "%matplotlib inline\n",
        "from matplotlib import rcParams\n",
        "\n",
        "\n",
        "import seaborn as sns              # for making plots with seaborn\n",
        "color = sns.color_palette()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLxAuPuZBMPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c94146b6-d24a-4664-f2ce-a68c9c1735e6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHEH5YFKBOh-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "d9c7337e-6b4b-44a6-8597-a6aee72d3484"
      },
      "source": [
        "path  = \"/content/drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/\"\n",
        "\n",
        "play_store_df = pd.read_csv(path + \"Copy of Play Store Data.csv\")\n",
        "user_review_df = pd.read_csv(path + \"Copy of User Reviews.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9e960d27c0f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplay_store_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Copy of Play Store Data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0muser_review_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Copy of User Reviews.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/CAPSTONE PROJECT/Copy of Play Store Data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkgylW-hB3ic"
      },
      "source": [
        "play_store_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFT2yXZECDPz"
      },
      "source": [
        "print(play_store_df.shape)\n",
        "print(user_review_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2aFQBP1CKxL"
      },
      "source": [
        "#**Task 1: DATA CLEANING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSqrVj-eN7SS"
      },
      "source": [
        "#**1) Finding missing value and treat them**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHjyTz2XCH4P"
      },
      "source": [
        "# First we need to find missing value in our data\n",
        "print( ' ' ' missing value is as following' + '\\n\\n' + ' ' '*'*20)\n",
        "\n",
        "play_store_df.isnull().sum()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60t9HJUpCUi5"
      },
      "source": [
        "Data can contain duplicate,NaN type,wrong data type so that we need to clean our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTO9fQ6fCRUm"
      },
      "source": [
        "#checking for duplicates\n",
        "play_store_df[play_store_df.duplicated(subset=['App'], keep='first')]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxfg5SJECXXS"
      },
      "source": [
        "#delete duplicates from App column.\n",
        "play_store_df.drop_duplicates(subset=['App'],keep='first', inplace=True, ignore_index=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZMbO85vCfaM"
      },
      "source": [
        "check data remove or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxIk01qXCb7Z"
      },
      "source": [
        "play_store_df[play_store_df.duplicated(subset=['App'], keep='first')]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxVA1w_ECiIh"
      },
      "source": [
        "play_store_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S60u4Ke2CkiS"
      },
      "source": [
        "play_store_df.isnull().sum()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szZAWyCQCqZt"
      },
      "source": [
        "Here you can see that Rating seem to have a very high number of missing observations. The current ver, Android ver and content rating also have missing values, as you can see, but they’re pretty negligible compared to Rating.\n",
        "\n",
        "Replace all null value with their appropriate values use **aggregate function** such as **mean,mode,median**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zICC_wm8OHkA"
      },
      "source": [
        "#**Task 2 :**\n",
        "\n",
        "#**2)Correcting data type**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBE5G7hfCm-C"
      },
      "source": [
        "# Replacing the null values with the median in the rating column.\n",
        "\n",
        "median_val =round(play_store_df['Rating'].median(),2)\n",
        "#median_val\n",
        "play_store_df['Rating'].fillna(median_val,inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1HHkmmrCxlD"
      },
      "source": [
        "play_store_df['Current Ver'].fillna(play_store_df['Current Ver'].mode()[0],inplace=True)\n",
        "play_store_df['Android Ver'].fillna(play_store_df['Android Ver'].mode()[0],inplace=True)\n",
        "play_store_df['Content Rating'].fillna(play_store_df['Content Rating'].mode()[0],inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayLgjXUyC3nd"
      },
      "source": [
        "# Finding the mod values of column and replacing it null values.\n",
        "\n",
        "mode_val_type = play_store_df['Type'].mode()[0]\n",
        "mode_val_type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jXGqBDEC5EL"
      },
      "source": [
        "play_store_df['Type'].fillna(mode_val_type,inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8WYJPL3C7nS"
      },
      "source": [
        "play_store_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7blgZkjC-za"
      },
      "source": [
        "play_store_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neR6uhzkO4Tz"
      },
      "source": [
        "#**Task 3**\n",
        "\n",
        "#**Checking**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dBTW7pLDHAl"
      },
      "source": [
        "**Checking outliers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHALwzF4DL9F"
      },
      "source": [
        "\n",
        "\n",
        "*   In playstore rating done between 1 to 5 so we need to drop any rating other than this\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIuLgwk6DCt4"
      },
      "source": [
        "play_store_df[play_store_df.Rating<1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwhM2IV7DTMF"
      },
      "source": [
        "play_store_df[play_store_df['Rating']>5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2D5r_AbDVKX"
      },
      "source": [
        "play_store_df.drop([9300],inplace=True)   # drop record rating >5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8cdCnhPDYD3"
      },
      "source": [
        "play_store_df.boxplot(column='Rating')\n",
        "plt.grid(False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d-0JPg4Ddv6"
      },
      "source": [
        "it shows there is no rating present below 1 and above 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlqwTzeDD3Kx"
      },
      "source": [
        "clean data more precisely each column wise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byU0GOZmDaLn"
      },
      "source": [
        "# We need to clean data\n",
        "# remove '+' and ',' in Installs column\n",
        "\n",
        "play_store_df['Installs']=play_store_df['Installs'].apply(lambda x: x.replace('+','') if '+' in str(x) else x)\n",
        "play_store_df['Installs']=play_store_df['Installs'].apply(lambda x: x.replace(',','') if ',' in str(x) else x)\n",
        "\n",
        "play_store_df = play_store_df[~(play_store_df['Installs'] == \"Free\")].reset_index(drop=True)  #drop  Free from Installs column\n",
        "\n",
        "play_store_df['Installs']=play_store_df['Installs'].apply(lambda x: int(x)) # convert to int\n",
        "\n",
        "# Remove '$' from Price column and change to float type\n",
        "play_store_df['Price']=play_store_df['Price'].apply(lambda x: x.replace('$','') if '$' in str(x) else x)\n",
        "play_store_df['Price']=play_store_df['Price'].apply(lambda x: float(x))\n",
        "\n",
        "play_store_df = play_store_df[~(play_store_df['Price'] == \"Everyone\")].reset_index(drop=True)  #drop 'Everyone from Price column\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUsf5I7wD8lW"
      },
      "source": [
        "play_store_df = play_store_df[~(play_store_df['Size'] == \"Varies with device\")].reset_index(drop=True)  #drop Varies with device from Price column\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPReAqojD-1u"
      },
      "source": [
        "play_store_df['Size']=play_store_df['Size'].apply(lambda x: str(x).replace('M','').replace('+','').replace(',','') if 'M' in str(x) else x)\n",
        "\n",
        "# need to convert kb to Mb formula Mb=kb/1024\n",
        "\n",
        "play_store_df['Size']=play_store_df['Size'].apply(lambda x: float(str(x).replace('k',''))/1024 if 'k' in str(x) else x)\n",
        "\n",
        "\n",
        "\n",
        "### change datatype with respect to their data\n",
        "play_store_df['Size']=play_store_df['Size'].astype(float)\n",
        "play_store_df['Reviews']=play_store_df['Reviews'].astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing - and values from column\n",
        "def hyphen_removal(data):\n",
        "  split_string = data.split(\"-\", 1)\n",
        "  substring = split_string[0]\n",
        "  return substring\n",
        "# Removing data after second dot\n",
        "def irregular_data(text):\n",
        "  k=  (text.find(\".\")) #find \".\" in a string\n",
        "  m = (text.find(\".\", k+1)) #Find second \".\" in a string\n",
        "  new_string = text[:m]\n",
        "  return new_string\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "play_store_df['Android Ver']=play_store_df['Android Ver'].apply(lambda x: hyphen_values_removal(x) if '-' in str(x) else x)\n",
        "play_store_df['Android Ver']=play_store_df['Android Ver'].apply(lambda x: irregular_data(x) if '.' in str(x) else x)"
      ],
      "metadata": {
        "id": "bbx8W-3JM4tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_LDBTdQEDhK"
      },
      "source": [
        "change datatype of last updated to datetime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jGN4ZalEBEV"
      },
      "source": [
        "play_store_df['Last Updated'] = pd.to_datetime(play_store_df['Last Updated'])\n",
        "#play_store_df['Last Updated']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYu0hvACEGqt"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twj7pS_iFFqv"
      },
      "source": [
        "play store review should not more than installs so we need to check data for same"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu4OX6DbEJnV"
      },
      "source": [
        "play_store_df.loc[play_store_df['Reviews']>play_store_df['Installs']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xReZV5wlErOD"
      },
      "source": [
        "# removing fake data firstly store in temporary variable\n",
        "temp_= play_store_df.loc[play_store_df['Reviews']>play_store_df['Installs']].index\n",
        "play_store_df.drop(labels=temp_,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDMMO62kFM_F"
      },
      "source": [
        "play_store_df.loc[play_store_df['Reviews']>play_store_df['Installs']]    #checking"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-1Q04_CFRZR"
      },
      "source": [
        "play_store_df.isnull().sum()    # missing value procedure done"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pamr1jjlFiam"
      },
      "source": [
        "#**Correct Data Type**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDzwV2YjFUYB"
      },
      "source": [
        "play_store_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFHagghMPcmw"
      },
      "source": [
        "#**Exploratory Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS7-p4HTF5na"
      },
      "source": [
        "#**1)Basic observation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRWQ8pjvF-dy"
      },
      "source": [
        "**Average App Rating**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWF76BCUFW-x"
      },
      "source": [
        "play_store_df['Rating'].mean()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fja0K8I3GGtX"
      },
      "source": [
        "**Find top five category getting Higest average Rating**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ocA5q6IGEwN"
      },
      "source": [
        "play_store_df.groupby('Category')['Rating'].mean().sort_values(ascending=False).head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQmZIP8lGQWi"
      },
      "source": [
        "**Find app with 5 star rating**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7IaaHPPGKIK"
      },
      "source": [
        "play_store_df[play_store_df['Rating']==5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmtx2cwZGWja"
      },
      "source": [
        "**Total number of free and paid apps**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVpmHm4QGT6m"
      },
      "source": [
        "play_store_df['Type'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNy0mrtmV1GL"
      },
      "source": [
        "play_store_df['Price'].max() # max paid app on play store"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39MzqNuMGfEy"
      },
      "source": [
        "**find app which has maximum reviews**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_wYVgC6GcUe"
      },
      "source": [
        "app_name=play_store_df[play_store_df['Reviews'].max()==play_store_df['Reviews']]['App'].index\n",
        "\n",
        "play_store_df['App'][app_name]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKSWBHZxGmx6"
      },
      "source": [
        "**Display top 5 Apps having highest reviews**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9beBtPxGj19"
      },
      "source": [
        "index1=play_store_df['Reviews'].sort_values(ascending=False).head().index\n",
        "\n",
        "play_store_df.iloc[index1]['App']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb8wpJlxWtzl"
      },
      "source": [
        "expensive_apps = play_store_df.loc[play_store_df['Price'] >=250]\n",
        "\n",
        "expensive_apps.loc[:, [\"App\", \"Category\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4-Yy_z1W_zE"
      },
      "source": [
        "expensive_apps[\"Installs\"].groupby(expensive_apps[\"App\"]).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHsIgiBgW-X-"
      },
      "source": [
        " among most expensive app **I'm rich** most popular app with highest installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FwUt4LAXqBk"
      },
      "source": [
        "sns.scatterplot(x=\"Category\", y=\"Price\",data=play_store_df)\n",
        "\n",
        "plt.xticks(rotation=90)\n",
        "plt.figure(figsize=(30,9))\n",
        "rcParams['figure.figsize'] = 30,9\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7RMuV-WZam6"
      },
      "source": [
        "*  Ignoring the catogories with price > 100$\n",
        "\n",
        "*  **Medical and Family** apps are the most expensive. Some medical apps extend even upto 80$.\n",
        "\n",
        "*  All other apps are priced under 50$.\n",
        "\n",
        "*  Shocking..... all game apps are reasonably priced below 20$.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZO_sxh1Gsjq"
      },
      "source": [
        "**Display top 5 app having maximum Installs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EApXDnrGqgG"
      },
      "source": [
        "install=play_store_df['Installs'].sort_values(ascending=False).head().index\n",
        "play_store_df.iloc[install]['App']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyO_t_TEGyrJ"
      },
      "source": [
        "#**DATA VISUALIZATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw4y0V6UGwZl"
      },
      "source": [
        "grp=play_store_df.groupby('Category')\n",
        "x=grp['Installs'].agg(np.mean)\n",
        "y=grp['Price'].agg(np.sum)\n",
        "z=grp['Reviews'].agg(np.mean)\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V5xxzsJG5LE"
      },
      "source": [
        "plt.figure(figsize=(18,6))\n",
        "\n",
        "ax = sns.countplot(x=\"Category\",data=play_store_df,palette=\"Paired\")\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"right\")\n",
        "ax\n",
        "plt.title('Categorywise count of app',size = 18)\n",
        "ax.grid(False)\n",
        "sns.set_style('white')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6RAa9RSHBFp"
      },
      "source": [
        "\n",
        "\n",
        "*   Game and family subsequently catch high number of market place.\n",
        "\n",
        "\n",
        "*   Tools,medical and business aslo catch market prevelance\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhAugt5QHZsX"
      },
      "source": [
        "**Rating of apps**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otDMPmT7G9Rk"
      },
      "source": [
        "#plot histogram from rating column\n",
        "plt.figure(figsize=(13,8))\n",
        "print(f\"average rating for app is {round(play_store_df['Rating'].mean(),5)}\")\n",
        "\n",
        "play_store_df['Rating'].hist(color='b')\n",
        "plt.title('Google play app rating distribution')\n",
        "plt.ylabel('App count')\n",
        "plt.xlabel('Rating out of 5')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed49PhOlHf84"
      },
      "source": [
        "This histogram shows max **rating** is distributed **4.1 above**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbBJE3VBHljP"
      },
      "source": [
        "#**App size light or bulky?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWOuWN8eHdmj"
      },
      "source": [
        "\n",
        "# draw jointplot with\n",
        "# hex kind\n",
        "sns.jointplot(x = \"Rating\", y = \"Size\",\n",
        "              kind = \"hex\",color='b', data = play_store_df)\n",
        "plt.ylabel('Size in MB --->')\n",
        "plt.xlabel('Rating ----->')\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bulky_apps = play_store_df[play_store_df[\"Size\"]>40]\n",
        "group_category = bulky_apps.groupby(\"Category\")[\"Size\"].count().sort_values(ascending=False).reset_index().head()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.set(font_scale=1)\n",
        "sns.set_style(\"darkgrid\")\n",
        "ax = sns.barplot(x=\"Category\", y=\"Size\", data=group_category, color = \"darkcyan\")\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"right\")\n",
        "plt.title('Count of Bulky Apps per Category',size = 14)\n",
        "plt.savefig(\"Count_bulky\")"
      ],
      "metadata": {
        "id": "BqKPEqXDjGXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmYqrePFH1sx"
      },
      "source": [
        "\n",
        "\n",
        "*   From above join plot we can conculde that most of good rating app i.e between 4-4.5 is having size 0.1-40MB.\n",
        "\n",
        "*   generally we see high rating means high size apps that not always true.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waD8aeGhH8x9"
      },
      "source": [
        "**Price category**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPnNmx7ZHrH6"
      },
      "source": [
        "play_store_df['Type'].value_counts().plot.pie(figsize=(12,8),autopct='%1.1f%%',textprops= {'fontsize': 14},subplots=True)\n",
        "plt.title('App type')\n",
        "plt.ylabel('')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD4w9FF3IA2x"
      },
      "source": [
        "play_store_df['Type'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS2TCKERINvu"
      },
      "source": [
        "It shows paid app are lower in number than free app."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD9GLLMPwszC"
      },
      "source": [
        "**Analysing Content Rating of app**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UycOo7Vz3z0"
      },
      "source": [
        "play_store_df['Content Rating'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQnDiwBr0DOj"
      },
      "source": [
        "unrated and adults only 18+ have very few records we can drop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mx3Drdx0UzH"
      },
      "source": [
        "play_store_df.drop(play_store_df[play_store_df['Content Rating']=='Unrated'].index,inplace=True)\n",
        "play_store_df.drop(play_store_df[play_store_df['Content Rating']=='Adults only 18+'].index,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F5M5sv5IKmQ"
      },
      "source": [
        "plt.figure(figsize=(7,6))\n",
        "plt.xticks(rotation = 35, ha = 'right')\n",
        "ax = sns.countplot(x='Content Rating',data=play_store_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdMb-OyMyuMf"
      },
      "source": [
        "This shows most of app present on play store is for everyone means there is no age restriction to use app."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p5CrJwXRgTy"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUfuvmaOQKU0"
      },
      "source": [
        "# We Plot the pie chart for Content rating & showing their percentages\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.char.array(['Everyone','Teen','Mature 17+','Everyone 10+','Adults only 18+','Unrated'])\n",
        "y = np.array([7903, 1036,393,322, 3, 2])\n",
        "colors = ['lightskyblue', 'red', 'gold','yellowgreen' ,'blue', 'darkgreen']\n",
        "porcent = 100.*y/y.sum()\n",
        "\n",
        "patches, texts = plt.pie(y, colors=colors,shadow=True, startangle=360, radius=1.3)\n",
        "labels = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(x, porcent)]\n",
        "\n",
        "sort_legend = True\n",
        "if sort_legend:\n",
        "    patches, labels, dummy =  zip(*sorted(zip(patches, labels, y),\n",
        "                                          key=lambda x: x[2],\n",
        "                                          reverse=True))\n",
        "\n",
        "plt.legend(patches, labels,title='Content Rating Pie Chart', loc='right center', bbox_to_anchor=(1.2, 1.),\n",
        "           fontsize=20)\n",
        "plt.savefig('piechart.png', bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMy8TELA2yex"
      },
      "source": [
        "**corr for pairwise correlation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5L7Jh1ax9FC"
      },
      "source": [
        "corr=play_store_df.corr()\n",
        "corr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmS-GNDH3UV-"
      },
      "source": [
        "#plot heatmap\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "\n",
        "sns.heatmap(corr,  vmax=.3, center=0, cmap=\"RdBu\",annot=True,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "\n",
        "plt.gcf().set_size_inches(15, 8)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpzDLAlhzk1t"
      },
      "source": [
        "*  A moderate positive correlation of 0.6 exists between the number of reviews and number of downloads. This means that customers tend to download a given app more if it has been reviewed by a larger number of people.\n",
        "\n",
        "*  This shows that many active users who download an app usually also leave back a review or feedback.\n",
        "\n",
        "*  So, getting your app reviewed by more people maybe a good idea to increase your app's capture in the market!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYvTVjRG9NyF"
      },
      "source": [
        "#**Analysis of sentiment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROOfEjsYuZHc"
      },
      "source": [
        "App User reviews data can be analyzed to identify customers´ mood: positive, negative or neutral, e.g:\n",
        "\n",
        "* Positive:'amazing', 'friendly', 'good', 'great', and 'love'.\n",
        "* Negative: 'malware', 'hate', 'problem', 'refund', and 'incompetent'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Casi_dXP9TBW"
      },
      "source": [
        "user_review_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOkSSxRF92N1"
      },
      "source": [
        "user_review_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UonBrPYh-3p3"
      },
      "source": [
        "**Merge** original datatype contain **App** and **Type** with this  current dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFc1IKmN-Jzz"
      },
      "source": [
        "sentiment_df=pd.merge(user_review_df,play_store_df[['App','Type','Price']],how='inner',on='App')\n",
        "\n",
        "#After this drop null value\n",
        "sentiment_df = sentiment_df.dropna()\n",
        "sentiment_df.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlN_2_RS_4la"
      },
      "source": [
        "sentiment_df['Type'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvyXuVRoqRvH"
      },
      "source": [
        "sentiment_df.isnull().sum()  # no null values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvHY3sU9CvuO"
      },
      "source": [
        "sentiment_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQZnyI_rSIe2"
      },
      "source": [
        "We need to find Paid and free sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2ep8qdRSO0R"
      },
      "source": [
        "# A dataframe for each app type\n",
        "free_apps = sentiment_df[sentiment_df[\"Type\"] == \"Free\"]\n",
        "paid_apps = sentiment_df[sentiment_df[\"Type\"] == \"Paid\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ6cUIirSUdS"
      },
      "source": [
        "# Return normalized values (percentages).\n",
        "print(\"Free Apps - Sentiment Percentage \\n\" + \"-\"*30 + \"\\n{}\\n\\n\".format(free_apps['Sentiment'].value_counts(normalize=True) * 100))\n",
        "print(\"Paid Apps - Sentiment Percentage \\n\" + \"-\"*30 +\"\\n{}\".format(paid_apps['Sentiment'].value_counts(normalize=True) * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70o105hOSh_d"
      },
      "source": [
        "# Reset index, then drop the old index column when it is moved to the right as a new column\n",
        "paid_apps = paid_apps.reset_index().drop(columns=[\"index\"])\n",
        "free_apps = free_apps.reset_index().drop(columns=[\"index\"])\n",
        "\n",
        "# Generate a list of random indexes applicable to free_apps\n",
        "random_indexes = np.random.choice(len(free_apps)-1, len(paid_apps), replace=False)\n",
        "\n",
        "# Shorten free_apps to the same size of paid_apps & using a random selection\n",
        "free_apps = free_apps.iloc[random_indexes]\n",
        "\n",
        "# Reset index of free_apps\n",
        "free_apps = free_apps.reset_index().drop(columns=[\"index\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA7CKIZeSp9i"
      },
      "source": [
        "# Generate values & counts for Sentiment columns in our dataframes & put them in dictionaries\n",
        "val_ct_free = np.unique(free_apps['Sentiment'],return_counts=True)\n",
        "free_data = {value: count for value, count in zip(val_ct_free[0],val_ct_free[1])}\n",
        "\n",
        "val_ct_paid = np.unique(paid_apps['Sentiment'],return_counts=True)\n",
        "paid_data = {value: count for value, count in zip(val_ct_paid[0],val_ct_paid[1])}\n",
        "\n",
        "\n",
        "# Put values and counts each in a different variable for use in plots, taken from dictionaries\n",
        "free_names = list(free_data.keys())\n",
        "free_values = list(free_data.values())\n",
        "paid_names = list(paid_data.keys())\n",
        "paid_values = list(paid_data.values())\n",
        "\n",
        "\n",
        "# Create a figure containing plots for each app type, sharing the y-axis for comparison\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 6),sharey=True)\n",
        "axs[0].bar(free_names, free_values)\n",
        "axs[0].set_title(\"Free App Sentiments\")\n",
        "axs[1].bar(paid_names, paid_values)\n",
        "axs[1].set_title(\"Paid App Sentiments\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VswbfJfVSyI9"
      },
      "source": [
        "Free apps as we can see negative as well as neutral review so high varience.\n",
        "paid app has more positive review very less neutral and negative reviews as comapre to postive reviews\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZZq0MVTTvQu"
      },
      "source": [
        "#**sentiment analysis based on category**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7ElLLlqUThT"
      },
      "source": [
        "# First we merge the Category & App of 1st data set to App column in 2nd data set\n",
        "category_df = pd.merge(sentiment_df, play_store_df[[\"App\",\"Category\"]] , how='inner', on=\"App\")\n",
        "\n",
        "# Drop all nan values\n",
        "category_df =category_df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLIb8fVjUDA_"
      },
      "source": [
        "from matplotlib.ticker import PercentFormatter\n",
        "\n",
        "f = plt.figure(figsize=(15,8))\n",
        "ax = f.add_subplot(1,1,1)\n",
        "\n",
        "sns.histplot(\n",
        "    category_df,\n",
        "    x=\"Category\", hue=\"Sentiment\",\n",
        "    bins=34,\n",
        "    ax=ax,\n",
        "    stat=\"count\",\n",
        "    multiple=\"stack\",\n",
        "    palette=\"light:m_r\",\n",
        "    edgecolor=\".3\",\n",
        "    linewidth=.5,\n",
        "    legend=True\n",
        "    )\n",
        "\n",
        "\n",
        "ax.set_title(\"Sentiment Analysis Based on Category\",fontsize=15,fontweight='bold')\n",
        "plt.xticks(rotation='vertical')\n",
        "ax.set_xlabel(\"Category\",fontsize=13)\n",
        "ax.set_ylabel(\"Review Counts\",fontsize=13)\n",
        "\n",
        "plt.gca().yaxis.set_major_formatter(PercentFormatter(20000))\n",
        "sns.set(style=\"ticks\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNH3tmRJU0MH"
      },
      "source": [
        "Family, Sports and Health & Fitness apps perform the best, Having more positive reviews\n",
        "\n",
        "On the contrary, many Game and Social apps perform decent leading to 50% positive and 50% negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV6gOawyArdq"
      },
      "source": [
        "#**Sentiment Polarity**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcFFfY5pAytx"
      },
      "source": [
        "-The polarity of a sentiment measures how negative or positive the context is.\n",
        "\n",
        "-In the data that we have, the polarity ranges from -1 (most negative) to +1 (most positive).\n",
        "\n",
        "Let's find out by plotting polarity for both free & paid app types:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-FrIsrnu3Rr"
      },
      "source": [
        "sns.set_style('ticks')\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(8, 4)\n",
        "\n",
        "# User review sentiment polarity for paid vs. free apps\n",
        "ax = sns.boxplot(x = 'Type', y = 'Sentiment_Polarity', data = sentiment_df)\n",
        "ax.set_title('Sentiment Polarity Distribution')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OCRN_PTMIWq"
      },
      "source": [
        "#**WORDCLOUD -quick overlook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnlxrBxxMWNg"
      },
      "source": [
        "**for free app**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbI21sFuLdXS"
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "free_apps = sentiment_df[sentiment_df[\"Type\"] == \"Free\"]\n",
        "\n",
        "\n",
        "comment_words = ''\n",
        "stopwords = set(STOPWORDS)\n",
        "\n",
        "# iterate through the csv file\n",
        "for val in free_apps.Translated_Review:\n",
        "\n",
        "    # typecaste each val to string\n",
        "    val = str(val)\n",
        "\n",
        "    # split the value\n",
        "    tokens = val.split()\n",
        "\n",
        "    # Converts each token into lowercase\n",
        "    for i in range(len(tokens)):\n",
        "        tokens[i] = tokens[i].lower()\n",
        "\n",
        "    comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "wordcloud = WordCloud(width = 800, height = 800,\n",
        "                background_color ='white',\n",
        "                stopwords = stopwords,\n",
        "                min_font_size = 10).generate(comment_words)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# plot the WordCloud image\n",
        "plt.figure(figsize = (7, 7), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G__SbB7wMalW"
      },
      "source": [
        "**For paid app**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucJ7_mQXLdm9"
      },
      "source": [
        "paid_apps = sentiment_df[sentiment_df[\"Type\"] == \"Paid\"]\n",
        "\n",
        "\n",
        "comment_words = ''\n",
        "stopwords = set(STOPWORDS)\n",
        "\n",
        "# iterate through the csv file\n",
        "for val in paid_apps.Translated_Review:\n",
        "\n",
        "    # typecaste each val to string\n",
        "    val = str(val)\n",
        "\n",
        "    # split the value\n",
        "    tokens = val.split()\n",
        "\n",
        "    # Converts each token into lowercase\n",
        "    for i in range(len(tokens)):\n",
        "        tokens[i] = tokens[i].lower()\n",
        "\n",
        "    comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "wordcloud = WordCloud(width = 800, height = 800,\n",
        "                background_color ='white',\n",
        "                stopwords = stopwords,\n",
        "                min_font_size = 10).generate(comment_words)\n",
        "\n",
        "\n",
        "\n",
        "# plot the WordCloud image\n",
        "plt.figure(figsize = (7, 7), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7bqdJUALdq2"
      },
      "source": [
        "sentiment_df['Sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVScXEQFNEWB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Merge the two datasets\n",
        "merged_df1 = play_store_df.merge(user_review_df, on = \"App\")\n",
        "merged_df1.head()\n",
        "\n",
        "## Drop the NA values\n",
        "merged_df1 = merged_df1.dropna(subset=['Translated_Review'])"
      ],
      "metadata": {
        "id": "0H3l2pA_ZvgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "wc = WordCloud(background_color=\"white\", max_words=250, colormap=\"Set2\")\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop = stopwords.words('english')\n",
        "stop = stop + ['app', 'APP' ,'ap', 'App', 'apps', 'application', 'browser', 'website', 'websites', 'chrome', 'click', 'web', 'ip', 'address',\n",
        "            'files', 'android', 'browse', 'service', 'use', 'one', 'download', 'email', 'Launcher','please','love','it','the','i',\n",
        "              'I','my','like','really','every','would','even','though','game','review']"
      ],
      "metadata": {
        "id": "4s8BjSuyRiFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Wordcloud Function\n",
        "def wc(data,bgcolor,title):\n",
        "    plt.figure(figsize = (100,100))\n",
        "    wc = WordCloud(background_color = bgcolor, max_words = 300,  max_font_size = 50, )\n",
        "    wc.generate(' '.join(data))\n",
        "    plt.imshow(wc)\n",
        "    plt.axis('off')\n",
        "    plt.title('Common Phrases in Reviews')"
      ],
      "metadata": {
        "id": "8ZMLKViqiWGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "## Frequency of words in translated review column\n",
        "from collections import Counter\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "#from stop_words import get_stop_words\n",
        "import re\n",
        "\n",
        "top_N = 100\n",
        "\n",
        "pos_review_lower = merged_df1[merged_df1['Sentiment']=='Positive']['Translated_Review'].str.lower().str.cat(sep=' ')\n",
        "neg_review_lower = merged_df1[merged_df1['Sentiment']=='Negative']['Translated_Review'].str.lower().str.cat(sep=' ')\n",
        "neu_review_lower = merged_df1[merged_df1['Sentiment']=='Neutral']['Translated_Review'].str.lower().str.cat(sep=' ')\n",
        "\n",
        "\n",
        "## Remove Punctuations\n",
        "pos_review_remove_pun = re.sub('[^A-Za-z]+', ' ', pos_review_lower)\n",
        "neg_review_remove_pun = re.sub('[^A-Za-z]+', ' ', neg_review_lower)\n",
        "neu_review_remove_pun = re.sub('[^A-Za-z]+', ' ', neu_review_lower)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wD2GR5ICcv59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove all the stopwords from the text\n",
        "pos_word_tokens_tags = word_tokenize(pos_review_remove_pun)\n",
        "neg_word_tokens_tags = word_tokenize(neg_review_remove_pun)\n",
        "neu_word_tokens_tags = word_tokenize(neu_review_remove_pun)\n",
        "pos_filtered_sentence_tags = [w_tags for w_tags in pos_word_tokens_tags if not w_tags in stop]\n",
        "pos_filtered_sentence_tags = []\n",
        "for w_tags in pos_word_tokens_tags:\n",
        "    if w_tags not in stop:\n",
        "        pos_filtered_sentence_tags.append(w_tags)\n",
        "\n",
        "neg_filtered_sentence_tags = [w_tags for w_tags in neg_word_tokens_tags if not w_tags in stop]\n",
        "neg_filtered_sentence_tags = []\n",
        "for w_tags in neg_word_tokens_tags:\n",
        "    if w_tags not in stop:\n",
        "        neg_filtered_sentence_tags.append(w_tags)\n",
        "\n",
        "neu_filtered_sentence_tags = [w_tags for w_tags in neu_word_tokens_tags if not w_tags in stop]\n",
        "neu_filtered_sentence_tags = []\n",
        "for w_tags in neu_word_tokens_tags:\n",
        "    if w_tags not in stop:\n",
        "        neu_filtered_sentence_tags.append(w_tags)"
      ],
      "metadata": {
        "id": "OakdYbSIczDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove characters which have length less than 2\n",
        "\n",
        "pos_without_single_chr_rev = [word_tags for word_tags in pos_filtered_sentence_tags if len(word_tags) > 2]\n",
        "neg_without_single_chr_rev = [word_tags for word_tags in neg_filtered_sentence_tags if len(word_tags) > 2]\n",
        "neu_without_single_chr_rev = [word_tags for word_tags in neu_filtered_sentence_tags if len(word_tags) > 2]\n"
      ],
      "metadata": {
        "id": "Qh5MAqjTc62h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC7uGWaMNEdM"
      },
      "source": [
        "## Wordcloud of Negative Reviews\n",
        "wc(neg_without_single_chr_rev,'white','Common Words' )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Wordcloud of Positive Reviews\n",
        "wc(pos_without_single_chr_rev,'white','Common Words' )\n"
      ],
      "metadata": {
        "id": "S4UqAP4_dT7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, this did not provide any tangible insights. Our aim was to analyse the reviews and get a better idea of the common issues that people face with apps or the attributes that make an app popular. To accomplish this, we proceeded to extract phrases (pairs of words) to get a better understanding that will support our analysis."
      ],
      "metadata": {
        "id": "vIuak-ASpbdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## let's see the distribution of postive, neg reviews in each category\n",
        "sentiment_count = merged_df1.groupby([\"Category\",\"Sentiment\"]).agg({'App': 'count'}).reset_index()\n",
        "sentiment_sum =  merged_df1.groupby(['Category']).agg({'Sentiment': 'count'}).reset_index()\n",
        "print(sentiment_sum.head())\n",
        "print(sentiment_count.head())"
      ],
      "metadata": {
        "id": "Yo0dqLz4bJpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Wordcloud Function\n",
        "def wc(data,bgcolor,title):\n",
        "    plt.figure(figsize = (100,100))\n",
        "    wc = WordCloud(background_color = bgcolor, max_words = 300,  max_font_size = 50, )\n",
        "    wc.generate(' '.join(data))\n",
        "    plt.imshow(wc)\n",
        "    plt.axis('off')\n",
        "    plt.title('Common Phrases in Reviews')"
      ],
      "metadata": {
        "id": "jk6ESSKWSIYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pair_split(x):\n",
        "    words = re.sub('[^A-Za-z_]+', ' ', x)\n",
        "    words = words.split()\n",
        "    words_new = [x for x in words if x not in stop]\n",
        "    if len(words_new) == 1:\n",
        "        return words_new\n",
        "    else:\n",
        "        pairs = [words_new[i]+'_'+words_new[i+1] for i in range(len(words_new)-1)]\n",
        "        return pairs"
      ],
      "metadata": {
        "id": "rqAsv3QNSN_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Frequency of words in translated review column\n",
        "from collections import Counter\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import re\n",
        "\n",
        "top_N = 100\n",
        "\n",
        "## Get every pair of words from the reviews\n",
        "\n",
        "pos_review_lower = merged_df1[merged_df1['Sentiment']=='Positive']['Translated_Review'].str.lower().apply(pair_split).apply(lambda x: \" \".join(x)).str.cat(sep=' ')\n",
        "neg_review_lower = merged_df1[merged_df1['Sentiment']=='Negative']['Translated_Review'].str.lower().apply(pair_split).apply(lambda x: \" \".join(x)).str.cat(sep=' ')\n",
        "\n",
        "pos_review_lower_rem = pos_review_lower.split(' ')\n",
        "pos_review_lower_rem = [a for a  in pos_review_lower_rem if a.find('_') >0]\n",
        "pos_review_remove_pun = \" \".join(pos_review_lower_rem)\n",
        "\n",
        "neg_review_lower_rem = neg_review_lower.split(' ')\n",
        "neg_review_lower_rem = [a for a  in neg_review_lower_rem if a.find('_') >0]\n",
        "neg_review_remove_pun = \" \".join(neg_review_lower_rem)\n",
        "\n"
      ],
      "metadata": {
        "id": "kqnrF-22SO1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_word_tokens_tags = word_tokenize(pos_review_remove_pun)\n",
        "neg_word_tokens_tags = word_tokenize(neg_review_remove_pun)\n",
        "\n",
        "pos_filtered_sentence_tags = [w_tags for w_tags in pos_word_tokens_tags if not w_tags in stop]\n",
        "pos_filtered_sentence_tags = []\n",
        "for w_tags in pos_word_tokens_tags:\n",
        "    if w_tags not in stop:\n",
        "        pos_filtered_sentence_tags.append(w_tags)\n",
        "\n",
        "neg_filtered_sentence_tags = [w_tags for w_tags in neg_word_tokens_tags if not w_tags in stop]\n",
        "neg_filtered_sentence_tags = []\n",
        "for w_tags in neg_word_tokens_tags:\n",
        "    if w_tags not in stop:\n",
        "        neg_filtered_sentence_tags.append(w_tags)\n",
        "\n"
      ],
      "metadata": {
        "id": "uDpBjZpESTx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove characters which have length less than 2\n",
        "\n",
        "pos_without_single_chr_rev = [word_tags for word_tags in pos_filtered_sentence_tags if len(word_tags) > 2]\n",
        "neg_without_single_chr_rev = [word_tags for word_tags in neg_filtered_sentence_tags if len(word_tags) > 2]\n"
      ],
      "metadata": {
        "id": "i5fZDsktSWdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts = Counter(neg_without_single_chr_rev)\n",
        "count_top30 = counts.most_common(10)\n",
        "count_top30"
      ],
      "metadata": {
        "id": "SBO9DwijSZX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_top30_df = pd.DataFrame(count_top30, columns=[\"Phrases\",\"Count\"])\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.set(font_scale=1)\n",
        "category_plot = sns.barplot(x=\"Phrases\",y =\"Count\",data=count_top30_df, palette = \"RdYlBu\")\n",
        "category_plot.set_xticklabels(category_plot.get_xticklabels(), rotation=90, ha=\"right\")\n",
        "plt.title('Common Phrases in Negative Reviews',size = 18)"
      ],
      "metadata": {
        "id": "fm4YH1HqSdfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "counts = Counter(pos_without_single_chr_rev)\n",
        "count_top30 = counts.most_common(10)\n",
        "count_top30"
      ],
      "metadata": {
        "id": "MLeyBMhQTba1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_top30_df = pd.DataFrame(count_top30, columns=[\"Phrases\",\"Count\"])\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.set(font_scale=1)\n",
        "category_plot = sns.barplot(x=\"Phrases\",y =\"Count\",data=count_top30_df, palette = \"YlGnBu_r\")\n",
        "category_plot.set_xticklabels(category_plot.get_xticklabels(), rotation=90, ha=\"right\")\n",
        "plt.title('Common Phrases in Positive Reviews',size = 18)"
      ],
      "metadata": {
        "id": "jLBIW4wYTe-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We extracted phrases from the reviews and observed that positive reviews had phrases like “many ads”, “free version”, “best ever” and “highly recommend”. The negative reviews contained phrases like “waste time”, “many ads”, “long time” and “worst ever”. We can see that loading time and ads were one of the main concerns amongst users. On the other hand, usability is one of the reasons that users give positive reviews."
      ],
      "metadata": {
        "id": "B3qhiKvBTjen"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogMmoueIBW2P"
      },
      "source": [
        "paid_apps=sentiment_df[sentiment_df['Type']=='Paid']\n",
        "\n",
        "free_apps=sentiment_df[sentiment_df['Type']=='Free']\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1hFiGscBEdo"
      },
      "source": [
        "\n",
        "polarity_free = free_apps[\"Sentiment_Polarity\"]\n",
        "\n",
        "# Plot two histograms showing sentiment polarity of each app type\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.hist(polarity_free, color=\"red\",alpha=.5, label=\"Free Apps\")\n",
        "\n",
        "plt.title('Sentiment Polarity Distribution For Free App')\n",
        "plt.xlabel('Sentiment Polarity')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7TCLFoxxeN6"
      },
      "source": [
        "*  When we look at this graph, we find that there is more neutral polarity in free apps, as shown by the larger red region just above the 0.00 on the x axis.\n",
        "\n",
        "*  As we see there is a more extreme positive polarity for free apps, as seen on the x axis in the range of 0.5 to 1.00.\n",
        "\n",
        "\n",
        "*  While some sentiments are exceptionally positive, none fall below -0.5, suggest greater overall satisfaction with paid apps and demonstrating a minimum cap for negative sentiments.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gckuq2BPD9K4"
      },
      "source": [
        "polarity_paid = paid_apps['Sentiment_Polarity']\n",
        "\n",
        "# Plot two histograms showing sentiment polarity of each app type\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.hist(polarity_paid, color=\"blue\",alpha=.5, label=\"Paid Apps\")\n",
        "\n",
        "plt.title('Sentiment Polarity Distribution For Paid Apps')\n",
        "plt.xlabel('Sentiment Polarity')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2EC7s-HxnwZ"
      },
      "source": [
        "*  For Paid apps, the majority of opinions fall somewhere between 0 and 0.5.\n",
        "\n",
        "*  some of sentiments are exceptionally positive, none fall below -0.5, suggesting greater overall satisfaction with paid apps and demonstrating a minimum cap for negative sentiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefaLotpIUdp"
      },
      "source": [
        "## **Final Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaActiFeTTK-"
      },
      "source": [
        "*  **Average rating** of (active) apps on Google Play Store is **4.18**\n",
        "\n",
        "*  Most  of user like light app and willing to pay for it also. Thus, a paid app that is bulky may not perform well in the market thats reason for getting good installs.\n",
        "\n",
        "*  Most of the **top rated apps are optimally sized between ~0.1MB to ~40MB - neither too light nor too heavy.**\n",
        "\n",
        "*  **Medical and Family** apps are the most expensive and even extend upto 80$.\n",
        "\n",
        "*  Users tend to download a given app more if it has been reviewed by a large number of people.\n",
        "\n",
        "*  Paid apps have a slightly higher number of favourable reviews than free apps.\n",
        "\n",
        "*  Free apps get more negative and neutral feedback, suggesting a wider range of opinions.\n",
        "\n",
        "*  **Clash of Clans** app has most number of reviews. While **Subway Surfers** is most number of install app\n",
        "\n",
        "*  When it comes to free apps, users are more pessimistic and harsh than when it comes to paid apps.\n",
        "\n",
        "*  More than half users rate **Family, Sports and Health & Fitness apps** positively. Apps for games and social media get mixed reviews, with 50 percent positive and 50 percent negative responses.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reference"
      ],
      "metadata": {
        "id": "K4FzDAhRVnu9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  www.stackovverflow.com\n",
        "*  www.jovian.ai         \n",
        "*  https://www.geeksforgeeks.org/implementing-web-scraping-python-beautiful-soup/"
      ],
      "metadata": {
        "id": "FrT8iJ5CVsQL"
      }
    }
  ]
}